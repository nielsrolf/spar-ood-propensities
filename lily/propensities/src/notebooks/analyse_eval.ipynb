{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d681156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── HONESTY RATE: Clarity x Cost ─────────────────────────\n",
      "\n",
      "base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b1188b78bc4276876bed58f3b0e9d9",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<inspect_viz._core.component.Component object at 0x145fc9f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finetuned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa707262088f4034badf727a877b72b4",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<inspect_viz._core.component.Component object at 0x1466129d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "── PUSHBACK MAINTENANCE: Pushback Type x Cost ───────────\n",
      "\n",
      "base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4f5de8ecce4caa9311923a8fe10286",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<inspect_viz._core.component.Component object at 0x145ace650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finetuned\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8029631f31fe4e4fb6cf3e30414e6002",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<inspect_viz._core.component.Component object at 0x145be7150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "── HONESTY + PUSHBACK: Base vs Finetuned ────────────────\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39241505f1a40c7b80c6ec9e9669024",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<inspect_viz._core.component.Component object at 0x145a3bd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from inspect_ai.analysis import samples_df\n",
    "from inspect_viz import Data\n",
    "from inspect_viz.plot import plot, legend\n",
    "from inspect_viz.mark import cell, text, bar_y\n",
    "\n",
    "df = samples_df(\"../evals/results/inspect\")\n",
    "CLAUDE_JUDGE_FILES = [\n",
    "    '../evals/results/inspect/base/honesty_eval/2026-02-22T23-02-24+00-00_honesty-eval_9NeaHRd62N3LtW69m6GAFx.eval',\n",
    "    '../evals/results/inspect/base/pushback_eval/2026-02-22T23-10-39+00-00_pushback-eval_4na78AdFByeVSG6qnryDH4.eval',\n",
    "    '../evals/results/inspect/finetuned/honesty_eval/2026-02-22T23-20-27+00-00_honesty-eval_WNLy55DTTBs3cMQ7LfAhSb.eval',\n",
    "    '../evals/results/inspect/finetuned/pushback_eval/2026-02-22T23-25-36+00-00_pushback-eval_h6XauAuZBqQYr4cXuirFtD.eval'\n",
    "]\n",
    "GPT_JUDGE_FILES = [\n",
    "    '../evals/results/inspect/base/honesty_eval/2026-02-24T00-24-04+00-00_honesty-eval_nSBVJNJKHnkuCv3pCP36jH.eval',\n",
    "    '../evals/results/inspect/base/pushback_eval/2026-02-24T00-38-18+00-00_pushback-eval_m9LBqUjL2nWKwKp77weuzE.eval',\n",
    "    '../evals/results/inspect/finetuned/honesty_eval/2026-02-24T00-49-57+00-00_honesty-eval_Rk6zds7wSZTquzwxjSGTTB.eval',\n",
    "    '../evals/results/inspect/finetuned/pushback_eval/2026-02-24T00-52-54+00-00_pushback-eval_SorZb6v2RqiMg23cMpAoxM.eval'\n",
    "]\n",
    "\n",
    "df = samples_df(GPT_JUDGE_FILES)\n",
    "\n",
    "honesty_df  = df[df[\"score_honesty_scorer\"].notna()].copy()\n",
    "pushback_df = df[df[\"score_pushback_scorer\"].notna()].copy()\n",
    "\n",
    "# ── Honesty heatmap ───────────────────────────────────────────────────────────\n",
    "\n",
    "honesty_agg = (\n",
    "    honesty_df\n",
    "    .groupby([\"log\", \"metadata_clarity\", \"metadata_cost\"])\n",
    "    [\"score_honesty_scorer\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"score_honesty_scorer\": \"honesty_rate\"})\n",
    ")\n",
    "\n",
    "print(\"── HONESTY RATE: Clarity x Cost ─────────────────────────\")\n",
    "for log_name, group in honesty_agg.groupby(\"log\"):\n",
    "    label = \"base\" if \"base\" in log_name else \"finetuned\"\n",
    "    group.to_parquet(\"/tmp/honesty_heatmap.parquet\", index=False)\n",
    "    data = Data.from_file(\"/tmp/honesty_heatmap.parquet\")\n",
    "    print(f\"\\n{label}\")\n",
    "    display(plot(\n",
    "        cell(data, x=\"metadata_cost\", y=\"metadata_clarity\", fill=\"honesty_rate\"),\n",
    "        text(data, x=\"metadata_cost\", y=\"metadata_clarity\", text=\"honesty_rate\", fill=\"white\"),\n",
    "        color_scheme=\"blues\",\n",
    "        x_label=\"Cost\", y_label=\"Clarity\",\n",
    "        margin_left=100,\n",
    "        height=250,\n",
    "    ))\n",
    "\n",
    "# ── Pushback heatmap ──────────────────────────────────────────────────────────\n",
    "\n",
    "pushback_agg = (\n",
    "    pushback_df\n",
    "    .groupby([\"log\", \"metadata_pushback_type\", \"metadata_cost\"])\n",
    "    [\"score_pushback_scorer\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"score_pushback_scorer\": \"maintenance_rate\"})\n",
    ")\n",
    "\n",
    "print(\"\\n── PUSHBACK MAINTENANCE: Pushback Type x Cost ───────────\")\n",
    "for log_name, group in pushback_agg.groupby(\"log\"):\n",
    "    label = \"base\" if \"base\" in log_name else \"finetuned\"\n",
    "    group.to_parquet(\"/tmp/pushback_heatmap.parquet\", index=False)\n",
    "    data = Data.from_file(\"/tmp/pushback_heatmap.parquet\")\n",
    "    print(f\"\\n{label}\")\n",
    "    display(plot(\n",
    "        cell(data, x=\"metadata_cost\", y=\"metadata_pushback_type\", fill=\"maintenance_rate\"),\n",
    "        text(data, x=\"metadata_cost\", y=\"metadata_pushback_type\", text=\"maintenance_rate\", fill=\"white\"),\n",
    "        color_scheme=\"greens\",\n",
    "        x_label=\"Cost\", y_label=\"Pushback Type\",\n",
    "        margin_left=100,\n",
    "        height=250,\n",
    "    ))\n",
    "\n",
    "# ── Overall scores bar chart ────────────────────────────────────────────────\n",
    "\n",
    "# Build a combined dataframe with scores from both tasks\n",
    "honesty_overall = (\n",
    "    honesty_df\n",
    "    .assign(model=honesty_df[\"log\"].apply(lambda x: \"base\" if \"base\" in x else \"finetuned\"))\n",
    "    .groupby(\"model\")[\"score_honesty_scorer\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"score_honesty_scorer\": \"score\"})\n",
    "    .assign(task=\"honesty\")\n",
    ")\n",
    "\n",
    "pushback_overall = (\n",
    "    pushback_df\n",
    "    .assign(model=pushback_df[\"log\"].apply(lambda x: \"base\" if \"base\" in x else \"finetuned\"))\n",
    "    .groupby(\"model\")[\"score_pushback_scorer\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"score_pushback_scorer\": \"score\"})\n",
    "    .assign(task=\"pushback\")\n",
    ")\n",
    "\n",
    "combined = pd.concat([honesty_overall, pushback_overall])\n",
    "combined.to_parquet(\"/tmp/combined_scores.parquet\", index=False)\n",
    "data = Data.from_file(\"/tmp/combined_scores.parquet\")\n",
    "\n",
    "print(\"\\n── HONESTY + PUSHBACK: Base vs Finetuned ────────────────\")\n",
    "display(plot(\n",
    "    bar_y(data, x=\"model\", y=\"score\", fill=\"task\", dodge=\"task\"),\n",
    "    legend=legend(\"color\"),\n",
    "    x_label=\"Model\",\n",
    "    y_label=\"Score\",\n",
    "    height=350,\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
